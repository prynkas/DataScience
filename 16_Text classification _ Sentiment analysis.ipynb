{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPU4Y6KLQOvl"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1D9x2uKV9smn5slG9JftecrbiSz00Rylz\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9zZ2ESqNrq1"
   },
   "source": [
    "Text classification & Sentiment analysis\n",
    "--\n",
    "\n",
    "Text classification – The aim of text classification is to automatically classify the text documents based on pretrained categories.\n",
    "\n",
    "Applications:\n",
    "--\n",
    "1. Sentiment Analysis\n",
    "2. Document classification\n",
    "3. Spam – ham mail classification\n",
    "4. Resume shortlisting\n",
    "5. Document summarization\n",
    "\n",
    "Problem\n",
    "--\n",
    "to do : Spam - ham classification using machine learning.\n",
    "\n",
    "Solution\n",
    "--\n",
    "If you observe, your Gmail has a folder called “Spam.” It will basically\n",
    "classify your emails into spam and ham so that you don’t have to read\n",
    "unnecessary emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1642090784614,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "IDQdbcnqNrq3",
    "outputId": "7ab74d92-7d7a-4705-ceca-a54995f546bc"
   },
   "outputs": [],
   "source": [
    "# Let’s follow the step-by-step method to build the classifier.\n",
    "\n",
    "# Step 1 :  Data collection and understanding\n",
    "# Please download data from the below link and save it in your working directory:\n",
    "# https://www.kaggle.com/uciml/sms-spam-collection-dataset#spam.csv\n",
    "\n",
    "import pandas as pd\n",
    "#Read the data\n",
    "Email_Data = pd.read_csv(\"spam.csv\",encoding ='latin1')\n",
    "\n",
    "#Data undestanding\n",
    "Email_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 2534,
     "status": "ok",
     "timestamp": 1642090793622,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "pCivLs6dNrrA",
    "outputId": "6286447e-7d65-42e6-fc84-95d92c7f1a69"
   },
   "outputs": [],
   "source": [
    "Email_Data = Email_Data[['v1', 'v2']]\n",
    "Email_Data = Email_Data.rename(columns={\"v1\":\"Target\",\"v2\":\"Email\"})\n",
    "Email_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1642090802206,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "THcipU2bNrrF"
   },
   "outputs": [],
   "source": [
    "# step 2 : Text processing and feature engineering\n",
    "\n",
    "# all imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1642090825412,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "iNyrNMjINrrL",
    "outputId": "f7e088a6-9ab7-4e62-db29-f61ffcf216f7"
   },
   "outputs": [],
   "source": [
    "#pre processing steps like lower case, stemming and lemmatization\n",
    "Email_Data['Email'] = Email_Data['Email'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "Email_Data['Email'] = Email_Data['Email'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "#st = PorterStemmer()\n",
    "#Email_Data['Email'] = Email_Data['Email'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "Email_Data['Email'] = Email_Data['Email'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "Email_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1642090830634,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "Jj2HwBthOwSO",
    "outputId": "9183946d-b5f9-4490-84a3-628ec3e63ed2"
   },
   "outputs": [],
   "source": [
    "# step 3:\n",
    "# Splitting data into train and validation\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(Email_Data['Email'], Email_Data['Target'])\n",
    "\n",
    "# TFIDF feature generation for a maximum of 5000 features\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "\n",
    "tfidf_vect.fit(Email_Data['Email'])\n",
    "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vect.transform(valid_x)\n",
    "print(xtrain_tfidf.data.shape)\n",
    "xtrain_tfidf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1642090835344,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "Hv40R-yuOr2X",
    "outputId": "09c89273-6327-4567-fc0e-39b0634fdcdc"
   },
   "outputs": [],
   "source": [
    "#tfidf_vect.vocabulary_\n",
    "\n",
    "#tfidf_vect.get_feature_names()\n",
    "print(xtrain_tfidf)\n",
    "\n",
    "# What is the element at index 4783 ?\n",
    "#Keys = [key  for (key, value) in tfidf_vect.vocabulary_.items() if value == 4783]\n",
    "#print(Keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1642090925034,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "xIHriKxWNrrV",
    "outputId": "b5ce69ab-b94a-4e49-d894-f0537087a6c5"
   },
   "outputs": [],
   "source": [
    "# step 4: \n",
    "# Model training\n",
    "# we have defined a generalized function for training any given model:\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label,feature_vector_valid, is_neural_net=False):\n",
    " # fit the training dataset on the classifier\n",
    " classifier.fit(feature_vector_train, label)\n",
    " # predict the labels on validation dataset\n",
    " predictions = classifier.predict(feature_vector_valid)\n",
    " return metrics.accuracy_score(predictions, valid_y)\n",
    "\n",
    "# Note : U can create any Classifier Object and pass it to the above fn, along \n",
    "# with the training & testing data\n",
    "# NaiveBayes Classifier\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(alpha=0.2),xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1642090941447,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "qF5WB11hNrrZ",
    "outputId": "bc4a18cd-820a-4214-b654-c6830fc13ab1"
   },
   "outputs": [],
   "source": [
    "# trying one more classifier, so that we can compare its performance with Naive Bayes\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(),xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"Accuracy: \", accuracy)\n",
    "\n",
    "# although LogisticRegression() is a binary classifier and performs well on such 2-class dataset\n",
    "# It did perform well. But not as well as NaiveBayes Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "wO7rby1ZNrrf"
   },
   "source": [
    "<font color='green'><b>Observation</b></font> : Naive Bayes is giving better results than the linear classifier. We can try many more classifiers and then choose the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh2fSwBUNrrg"
   },
   "source": [
    "Recalling Sentiment Analysis using TextBlob\n",
    "--\n",
    "In this section, we are going to discuss how to understand the sentiment of\n",
    "a particular sentence or statement. Sentiment analysis is one of the widely\n",
    "used techniques across the industries to understand the sentiments of the\n",
    "customers/users around the products/services. Sentiment analysis gives\n",
    "the sentiment score of a sentence/statement tending toward positive or negative.\n",
    "\n",
    "Problem\n",
    "--\n",
    "You want to do a sentiment analysis of **Amazon’s Alexa range of products**.\n",
    "\n",
    "Solution\n",
    "--\n",
    "The simplest way to do this by using a TextBlob or VADER library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YqvxmMoNrrh"
   },
   "source": [
    "How It Works\n",
    "--\n",
    "Let’s follow the steps in this section to do sentiment analysis using TextBlob. \n",
    "It will basically give 2 metrics.\n",
    "\n",
    "• <font color='green'>Polarity</font> = Polarity lies in the range of [-1,1] where 1 means a positive statement and -1 means a negative statement.\n",
    "\n",
    "• <font color='green'>Subjectivity</font> = Subjectivity can be between [0,1], where 0 means no subjectivity i.e 100% Objective and 1 means totally subjective i.e like your personal opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T04:23:25.377795Z",
     "start_time": "2024-02-19T04:23:25.342085Z"
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1642091864913,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "4W8JmbP7Nrri"
   },
   "outputs": [],
   "source": [
    "# Create the sample data\n",
    "#review = \"I like this phone. screen quality and camera clarity is really good.\"\n",
    "#review2 = \"This tv is not good. Bad quality, no clarity, worst experience\"\n",
    "\n",
    "# Recall the same function you had learned -> in NB 10 -> ML PRE-PROCESSING PIPELINE\n",
    "# Cleaning and preprocessing\n",
    "def processRow(row):\n",
    "    import re\n",
    "    import nltk\n",
    "    from textblob import TextBlob\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from textblob import Word\n",
    "    from nltk.util import ngrams\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "    #Lower case\n",
    "    row.lower()\n",
    "\n",
    "    #Removes unicode strings like \"\\u002c\"  -> ,(comma)\n",
    "    row= re.sub(r'(\\\\u[0-9A-Fa-f]+)',r'', row)\n",
    "\n",
    "    # Removes non-ascii characters. note : \\x00 to \\x7f is 00 to 255\n",
    "    # non-ascii characters like copyrigth symbol, trademark symbol\n",
    "    row = re.sub(r'[^\\x00-\\x7f]',r'',row)\n",
    "\n",
    "    #convert any url to URL\n",
    "    row = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',row)\n",
    "\n",
    "    #Convert any @Username to \"AT_USER\"\n",
    "    row = re.sub('@[^\\s]+','AT_USER',row)\n",
    "\n",
    "    #Remove additional white spaces\n",
    "    row = re.sub('[\\s]+', ' ', row)\n",
    "    row = re.sub('[\\n]+', ' ', row)\n",
    "\n",
    "    #Remove not alphanumeric symbols white spaces\n",
    "    row = re.sub(r'[^\\w]', ' ', row)\n",
    "\n",
    "    #Removes hastag in front of a word \"\"\"\n",
    "    row = re.sub(r'#([^\\s]+)', r'\\1', row)\n",
    "\n",
    "    #Replace #word with word\n",
    "    row = re.sub(r'#([^\\s]+)', r'\\1', row)\n",
    "\n",
    "    #Removes all possible emoticons\n",
    "    row = re.sub(':\\)|:\\(|:\\)|;\\)|:-\\)|\\(-:|:-D|=D|:P|xD|X-p|\\^\\^|:-|\\^\\.\\^|\\^\\-\\^|\\^\\_\\^|\\,-\\)|\\)-:|:\\'\\(|:\\(|:-\\(|:\\S|T\\.T|\\.\\_\\.|:<|:-\\S|:-<|\\\\-\\*|:O|=O|=\\-O|O\\.o|XO|O\\_O|:-\\@|=/|:/|X\\-\\(|>\\.<|>=\\(|D:', '', row)\n",
    "\n",
    "    #remove numbers -> this is optional\n",
    "    row = ''.join([i for i in row if not i.isdigit()])\n",
    "\n",
    "    #remove multiple exclamation -> this is optional\n",
    "    row = re.sub(r\"(\\!)\\1+\", ' ', row)\n",
    "\n",
    "    #remove multiple question marks -> this is optional\n",
    "    row = re.sub(r\"(\\?)\\1+\", ' ', row)\n",
    "\n",
    "    #remove multistop -> this is optional\n",
    "    row = re.sub(r\"(\\.)\\1+\", ' ', row)\n",
    "\n",
    "    #trim\n",
    "    row = row.strip('\\'\"')\n",
    "\n",
    "    #lemma\n",
    "    from textblob import Word\n",
    "    row =\" \".join([Word(word).lemmatize() for word in row.split()])\n",
    "\n",
    "    #stemmer\n",
    "    #st = PorterStemmer()\n",
    "    #row=\" \".join([st.stem(word) for word in row.split()])\n",
    "\n",
    "\n",
    "    return row\n",
    "               \n",
    "#call the function to process your data\n",
    "#review = processRow(review)\n",
    "#review2 = processRow(review2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T04:21:47.163370Z",
     "start_time": "2024-02-19T04:21:47.094602Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1642091869485,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "czcG1o1PNrrm",
    "outputId": "0ffb2f72-c034-4164-89e3-4a99219132a7"
   },
   "outputs": [],
   "source": [
    "# Get the sentiment scores\n",
    "# import libraries\n",
    "from textblob import TextBlob\n",
    "\n",
    "#TextBlob has a pre trained sentiment prediction model\n",
    "blob = TextBlob(review)\n",
    "blob.sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1642091874059,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "ya3DENypNrrq",
    "outputId": "3e91ef7d-1767-48dc-c464-57c7aaa49ead"
   },
   "outputs": [],
   "source": [
    "# Again using TextBlob, over review2\n",
    "# get the sentiment\n",
    "\n",
    "blob = TextBlob(review2)\n",
    "blob.sentiment\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "4oFOP0CFNrrw"
   },
   "source": [
    "**`Your Observation on both the reviews`** :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6aVlrrGLAKt"
   },
   "source": [
    "<hr>\n",
    "Sentiment analysis of <font color='green'><b>Amazon’s Alexa range of products</b></font>.\n",
    "<hr>\n",
    "\n",
    "Data Source link : \n",
    "https://drive.google.com/open?id=1xpQVZHR84LJ3MX-UihL7noK0w1bOIQgV\n",
    "\n",
    "You can use this data to analyze Amazon’s Alexa product range; discover insights into consumer reviews :\n",
    "> how many positive reviews ? \n",
    "\n",
    "> how many negative reviews ?\n",
    "\n",
    "> And accordingly help digital marketers/ecomm portals to concentrate on positive reviewed products.\n",
    "\n",
    "<small>The dataset consists of a nearly 3000 Amazon customer reviews (input text), star ratings, date of review, variant and feedback of various amazon Alexa products like Alexa Echo, Echo dots, Alexa Firesticks etc. for learning how to train Machine for sentiment analysis. </small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T04:23:34.526982Z",
     "start_time": "2024-02-19T04:23:33.719117Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1642092095780,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "XAbfOiI5Lajg",
    "outputId": "91acffab-43aa-4621-fafa-d861cf21a221"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       date         variation  \\\n",
       "0       5  31-Jul-18  Charcoal Fabric    \n",
       "1       5  31-Jul-18  Charcoal Fabric    \n",
       "2       4  31-Jul-18    Walnut Finish    \n",
       "3       5  31-Jul-18  Charcoal Fabric    \n",
       "4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df_review = pandas.read_csv('amazon_alexa.csv', sep='\\t')\n",
    "df_review.head()\n",
    "\n",
    "# Note Feedback is already given to us (may be its hand coded) : \n",
    "# Feedback 1 -> indicates positive feedback\n",
    "# Feedback 0 -> indicates negative feedback\n",
    "\n",
    "# But in reality we would only get the customer reviews, isn't it.\n",
    "# so, lets ignore the feedback column and only use for assessing\n",
    "# TextBlob sentiment analyser o/p.\n",
    "\n",
    "# More-ever the feedback column doesn't even have Neutral feedbacks. \n",
    "# Like all feedbacks need not be +ve or -ve only ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T04:23:38.019768Z",
     "start_time": "2024-02-19T04:23:37.998854Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1642092154529,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "p8OJk102L4Vw",
    "outputId": "f8893ed2-f485-4abe-d147-03ad6ba5e5e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2893\n",
       "0     257\n",
       "Name: feedback, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets find no. of positive and negative reviews in the dataset.\n",
    "df_review['feedback'].value_counts()\n",
    "\n",
    "# Now , imagine we run the Sentiment analyser code over this \n",
    "# entire dataset, we shd get a similar ans. isn't it ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T04:23:51.875822Z",
     "start_time": "2024-02-19T04:23:42.929831Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1107,
     "status": "ok",
     "timestamp": 1642092303418,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "NghsLzbVL_xP",
    "outputId": "bf502d52-5662-423e-d3c4-b92e70a3aa0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "      <th>cleaned_verified_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "      <td>Love my Echo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "      <td>Loved it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes while playing a game you can answer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I have had a lot of fun with this thing My yr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating       date         variation  \\\n",
       "0       5  31-Jul-18  Charcoal Fabric    \n",
       "1       5  31-Jul-18  Charcoal Fabric    \n",
       "2       4  31-Jul-18    Walnut Finish    \n",
       "3       5  31-Jul-18  Charcoal Fabric    \n",
       "4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \\\n",
       "0                                      Love my Echo!         1   \n",
       "1                                          Loved it!         1   \n",
       "2  Sometimes while playing a game, you can answer...         1   \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1   \n",
       "4                                              Music         1   \n",
       "\n",
       "                            cleaned_verified_reviews  \n",
       "0                                       Love my Echo  \n",
       "1                                           Loved it  \n",
       "2  Sometimes while playing a game you can answer ...  \n",
       "3  I have had a lot of fun with this thing My yr ...  \n",
       "4                                              Music  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean your verified_reviews\n",
    "from textblob import TextBlob\n",
    "cleaned_verified_reviews = []\n",
    "\n",
    "for line in df_review['verified_reviews'] :\n",
    "    cleanLine = processRow(line) \n",
    "    cleaned_verified_reviews.append(cleanLine)\n",
    "    \n",
    "import numpy as np    \n",
    "df_review['cleaned_verified_reviews'] = np.asarray(cleaned_verified_reviews)\n",
    "\n",
    "df_review.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T04:23:57.333811Z",
     "start_time": "2024-02-19T04:23:57.319821Z"
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1642092443967,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "EaG1KArMMKgC"
   },
   "outputs": [],
   "source": [
    "# Let's define our sentiment analyzer function:\n",
    "def analyze_sentiment(cleaned_verified_reviews):\n",
    "    analysis = TextBlob(cleaned_verified_reviews)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T04:23:01.244381Z",
     "start_time": "2024-02-19T04:23:00.989063Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "executionInfo": {
     "elapsed": 1364,
     "status": "ok",
     "timestamp": 1642092764088,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "SCyUpAeFMLba",
    "outputId": "11f6478e-85ea-418a-e798-5437ed47992f"
   },
   "outputs": [],
   "source": [
    "# Lets find the Sentiment by calling the above defn fn.\n",
    "# create a new column called 'Sentiment'\n",
    "df_review['Sentiment'] = df_review['cleaned_verified_reviews'].apply(lambda x: analyze_sentiment(x))\n",
    "\n",
    "df_review[['cleaned_verified_reviews', 'Sentiment']].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1642092837210,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "Uvh3wCOBMbu3",
    "outputId": "1cc414ad-bcdb-41b4-d27b-8e15d55801af"
   },
   "outputs": [],
   "source": [
    "# no. of positive sentiment reviews\n",
    "df_review[df_review.Sentiment=='Positive'].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1642092852521,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "P0mKSOOQMf5L",
    "outputId": "4ea37157-07c7-4997-edb7-2cd700084658"
   },
   "outputs": [],
   "source": [
    "# no. of negative sentiment reviews\n",
    "df_review[df_review.Sentiment=='Negative'].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1642092876814,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "Ds7S83RDMjSw",
    "outputId": "2ffe25fd-c972-4a15-b451-11e7a0305cd2"
   },
   "outputs": [],
   "source": [
    "# no. of neutral sentiment reviews\n",
    "df_review[df_review.Sentiment=='Neutral'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1642092930612,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "4NzPT1RKMzN2",
    "outputId": "31ecd813-b75e-4196-e8d9-36f1e1eaff1f"
   },
   "outputs": [],
   "source": [
    "# lets add polarity also to the df\n",
    "df_review['polarity'] = df_review['cleaned_verified_reviews'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "\n",
    "df_review[['cleaned_verified_reviews', 'Sentiment', 'polarity']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1642092934404,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "6aiFz1vuM2oc",
    "outputId": "82d9942b-5583-4a0b-e98a-72e9959483f2"
   },
   "outputs": [],
   "source": [
    "print('5 random reviews with the highest positive sentiment polarity: \\n')\n",
    "cl = df_review.loc[df_review.polarity == 1, ['cleaned_verified_reviews']].sample(5).values\n",
    "for c in cl:\n",
    "    print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1642093073696,
     "user": {
      "displayName": "Manasi Kulkarni-Pandharkar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjigU_mtu2MoD3CChY-Fyw-Dt_d-g4KEQ1RljwXPg=s64",
      "userId": "12976938306301425115"
     },
     "user_tz": -330
    },
    "id": "B4eOME9LM7Z_",
    "outputId": "30899412-5795-4b89-ab1e-26be49329e06"
   },
   "outputs": [],
   "source": [
    "print('2 random reviews with the high negative sentiment polarity: \\n')\n",
    "# your code here\n",
    "cl = df_review.loc[df_review.polarity < -0.5, ['cleaned_verified_reviews']].sample(5).values\n",
    "for c in cl:\n",
    "    print(c[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJvm60cYYqkg"
   },
   "source": [
    "**Observation on the above reviews:**\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "16_Text classification & Sentiment analysis.ipynb",
   "provenance": [
    {
     "file_id": "1FFbcID1lBM1_RHbKFgqXnYU0KOvbTFaI",
     "timestamp": 1642088971506
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
